{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential,load_model\n",
    "import cupy as cp\n",
    "from keras.layers import LSTM\n",
    "from  tensorflow.keras.layers import LSTM,Dense,Activation,Dropout\n",
    "from  tensorflow.keras.callbacks import History,Callback,EarlyStopping\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101700, 24, 3)\n",
      "(101700, 3)\n",
      "(42300, 24, 3)\n",
      "(42300, 3)\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('D:/library/Github/Innovative-practice/library/csv/第三学期/trainX.h5', 'r')\n",
    "trainX = f['data']\n",
    "trainX  = cp.array(trainX)\n",
    "f.close()\n",
    "f = h5py.File('D:/library/Github/Innovative-practice/library/csv/第三学期/trainY.h5', 'r')\n",
    "trainY = f['data']\n",
    "trainY  = cp.array(trainY)\n",
    "f.close()\n",
    "f = h5py.File('D:/library/Github/Innovative-practice/library/csv/第三学期/testX.h5', 'r')\n",
    "testX = f['data']\n",
    "testX  = cp.array(testX)\n",
    "f.close()\n",
    "f = h5py.File('D:/library/Github/Innovative-practice/library/csv/第三学期/testY.h5', 'r')\n",
    "testY = f['data']\n",
    "testY  = cp.array(testY)\n",
    "f.close()\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#选择要测试kpi sms=0 call=1 internet=2\n",
    "kpi=1\n",
    "if kpi==0:\n",
    "    kpi_name='sms'\n",
    "elif kpi==1:\n",
    "    kpi_name='call'\n",
    "else:\n",
    "    kpi_name='internet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[753, 643, 6038]\n",
      "[947, 552, 4529]\n"
     ]
    }
   ],
   "source": [
    "#查找每个kpi最大值\n",
    "trainmax=[int(cp.max(trainX[:,:,0])),int(cp.max(trainX[:,:,1])),int(cp.max(trainX[:,:,2]))]\n",
    "testmax=[int(cp.max(testX[:,:,0])),int(cp.max(testX[:,:,1])),int(cp.max(testX[:,:,2]))]\n",
    "print(trainmax)\n",
    "print(testmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#归一化\n",
    "for i in range(3):\n",
    "    trainX[:,:,i] = trainX[:,:,i]/trainmax[i]\n",
    "    testX[:,:,i] = testX[:,:,i]/testmax[i]\n",
    "    trainY[:,i] = trainY[:,i]/trainmax[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101700, 1)\n",
      "(42300, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainY = cp.reshape(trainY[:,kpi], (trainY.shape[0], 1))\n",
    "testY = cp.reshape(testY[:,kpi], (testY.shape[0], 1))\n",
    "print(trainY.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 24, 40)            7040      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 40)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 40)                12960     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 40)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 41        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,041\n",
      "Trainable params: 20,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(40,input_shape=(trainX.shape[1],trainX.shape[2]),\n",
    "                   return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(40,return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(trainY.shape[1]))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1272/1272 [==============================] - 18s 9ms/step - loss: 0.0015 - accuracy: 0.0116 - val_loss: 0.0011 - val_accuracy: 0.0120\n",
      "Epoch 2/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 8.3332e-04 - accuracy: 0.0116 - val_loss: 5.7291e-04 - val_accuracy: 0.0120\n",
      "Epoch 3/200\n",
      "1272/1272 [==============================] - 10s 8ms/step - loss: 5.6376e-04 - accuracy: 0.0116 - val_loss: 5.2298e-04 - val_accuracy: 0.0120\n",
      "Epoch 4/200\n",
      "1272/1272 [==============================] - 10s 8ms/step - loss: 4.6474e-04 - accuracy: 0.0116 - val_loss: 4.3585e-04 - val_accuracy: 0.0120\n",
      "Epoch 5/200\n",
      "1272/1272 [==============================] - 11s 8ms/step - loss: 4.4601e-04 - accuracy: 0.0116 - val_loss: 3.7433e-04 - val_accuracy: 0.0120\n",
      "Epoch 6/200\n",
      "1272/1272 [==============================] - 11s 8ms/step - loss: 4.1727e-04 - accuracy: 0.0116 - val_loss: 3.5821e-04 - val_accuracy: 0.0120\n",
      "Epoch 7/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 3.9284e-04 - accuracy: 0.0116 - val_loss: 4.6437e-04 - val_accuracy: 0.0120\n",
      "Epoch 8/200\n",
      "1272/1272 [==============================] - 11s 8ms/step - loss: 3.7953e-04 - accuracy: 0.0116 - val_loss: 3.3550e-04 - val_accuracy: 0.0120\n",
      "Epoch 9/200\n",
      "1272/1272 [==============================] - 10s 8ms/step - loss: 3.6906e-04 - accuracy: 0.0116 - val_loss: 3.4034e-04 - val_accuracy: 0.0120\n",
      "Epoch 10/200\n",
      "1272/1272 [==============================] - 11s 8ms/step - loss: 3.5846e-04 - accuracy: 0.0116 - val_loss: 3.2803e-04 - val_accuracy: 0.0120\n",
      "Epoch 11/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 3.4862e-04 - accuracy: 0.0116 - val_loss: 3.2606e-04 - val_accuracy: 0.0120\n",
      "Epoch 12/200\n",
      "1272/1272 [==============================] - 10s 8ms/step - loss: 3.4954e-04 - accuracy: 0.0116 - val_loss: 3.1387e-04 - val_accuracy: 0.0120\n",
      "Epoch 13/200\n",
      "1272/1272 [==============================] - 11s 8ms/step - loss: 3.3645e-04 - accuracy: 0.0116 - val_loss: 3.2957e-04 - val_accuracy: 0.0120\n",
      "Epoch 14/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 3.3123e-04 - accuracy: 0.0116 - val_loss: 3.1007e-04 - val_accuracy: 0.0120\n",
      "Epoch 15/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 3.2561e-04 - accuracy: 0.0116 - val_loss: 2.9356e-04 - val_accuracy: 0.0120\n",
      "Epoch 16/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 3.2430e-04 - accuracy: 0.0116 - val_loss: 3.0583e-04 - val_accuracy: 0.0120\n",
      "Epoch 17/200\n",
      "1272/1272 [==============================] - 11s 8ms/step - loss: 3.2266e-04 - accuracy: 0.0116 - val_loss: 3.5995e-04 - val_accuracy: 0.0120\n",
      "Epoch 18/200\n",
      "1272/1272 [==============================] - 10s 8ms/step - loss: 3.1380e-04 - accuracy: 0.0116 - val_loss: 2.9898e-04 - val_accuracy: 0.0120\n",
      "Epoch 19/200\n",
      "1272/1272 [==============================] - 11s 8ms/step - loss: 3.2341e-04 - accuracy: 0.0116 - val_loss: 3.0018e-04 - val_accuracy: 0.0120\n",
      "Epoch 20/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 3.0682e-04 - accuracy: 0.0116 - val_loss: 3.2048e-04 - val_accuracy: 0.0120\n",
      "Epoch 21/200\n",
      "1272/1272 [==============================] - 10s 8ms/step - loss: 3.0993e-04 - accuracy: 0.0116 - val_loss: 3.1831e-04 - val_accuracy: 0.0120\n",
      "Epoch 22/200\n",
      "1272/1272 [==============================] - 10s 8ms/step - loss: 3.1205e-04 - accuracy: 0.0116 - val_loss: 2.7903e-04 - val_accuracy: 0.0120\n",
      "Epoch 23/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 3.1047e-04 - accuracy: 0.0116 - val_loss: 3.2172e-04 - val_accuracy: 0.0120\n",
      "Epoch 24/200\n",
      "1272/1272 [==============================] - 11s 8ms/step - loss: 3.0066e-04 - accuracy: 0.0116 - val_loss: 2.8681e-04 - val_accuracy: 0.0120\n",
      "Epoch 25/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 3.0103e-04 - accuracy: 0.0116 - val_loss: 3.3868e-04 - val_accuracy: 0.0120\n",
      "Epoch 26/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 3.0538e-04 - accuracy: 0.0116 - val_loss: 2.9700e-04 - val_accuracy: 0.0120\n",
      "Epoch 27/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 2.9955e-04 - accuracy: 0.0116 - val_loss: 3.1410e-04 - val_accuracy: 0.0120\n",
      "Epoch 28/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 2.9832e-04 - accuracy: 0.0116 - val_loss: 2.8419e-04 - val_accuracy: 0.0120\n",
      "Epoch 29/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 2.9411e-04 - accuracy: 0.0116 - val_loss: 2.6699e-04 - val_accuracy: 0.0120\n",
      "Epoch 30/200\n",
      "1272/1272 [==============================] - 11s 8ms/step - loss: 2.9688e-04 - accuracy: 0.0116 - val_loss: 2.9365e-04 - val_accuracy: 0.0120\n",
      "Epoch 31/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 2.9444e-04 - accuracy: 0.0116 - val_loss: 2.8890e-04 - val_accuracy: 0.0120\n",
      "Epoch 32/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 2.9289e-04 - accuracy: 0.0116 - val_loss: 3.0115e-04 - val_accuracy: 0.0120\n",
      "Epoch 33/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 2.9652e-04 - accuracy: 0.0116 - val_loss: 3.0350e-04 - val_accuracy: 0.0120\n",
      "Epoch 34/200\n",
      "1272/1272 [==============================] - 10s 8ms/step - loss: 2.9618e-04 - accuracy: 0.0116 - val_loss: 3.0552e-04 - val_accuracy: 0.0120\n",
      "Epoch 35/200\n",
      "1272/1272 [==============================] - 10s 8ms/step - loss: 2.9294e-04 - accuracy: 0.0116 - val_loss: 2.9850e-04 - val_accuracy: 0.0120\n",
      "Epoch 36/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 2.9151e-04 - accuracy: 0.0116 - val_loss: 2.8685e-04 - val_accuracy: 0.0120\n",
      "Epoch 37/200\n",
      "1272/1272 [==============================] - 11s 8ms/step - loss: 2.8632e-04 - accuracy: 0.0116 - val_loss: 3.0564e-04 - val_accuracy: 0.0120\n",
      "Epoch 38/200\n",
      "1272/1272 [==============================] - 11s 8ms/step - loss: 2.9411e-04 - accuracy: 0.0116 - val_loss: 2.8460e-04 - val_accuracy: 0.0120\n",
      "Epoch 39/200\n",
      "1272/1272 [==============================] - 11s 9ms/step - loss: 2.8462e-04 - accuracy: 0.0116 - val_loss: 2.9236e-04 - val_accuracy: 0.0120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cbs = [History(), EarlyStopping(monitor='val_loss',\n",
    "                                patience=10,\n",
    "                                min_delta=0.00001,\n",
    "                                verbose=0)]\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+kpi_name\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "history=model.fit(trainX.get(),\n",
    "        trainY.get(),\n",
    "        batch_size=64,\n",
    "        epochs=200,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[cbs,tensorboard_callback],\n",
    "        verbose=True)\n",
    "model.save(os.path.join(f\"D:\\library\\Github\\Innovative-practice\\第三学期\\DATA\\lstm\",f\"Test_{kpi_name}\" + \".h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir D:\\library\\Github\\Innovative-practice\\第三学期\\lstm\\logs\\fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3179/3179 [==============================] - 11s 3ms/step\n",
      "1322/1322 [==============================] - 4s 3ms/step\n",
      "(101700, 1)\n",
      "(42300, 1)\n"
     ]
    }
   ],
   "source": [
    "#预测\n",
    "model = load_model(os.path.join(f\"D:\\library\\Github\\Innovative-practice\\第三学期\\DATA\\lstm\",f\"Test_{kpi_name}\" + \".h5\"))\n",
    "trainPredict = model.predict(trainX.get())\n",
    "testPredict = model.predict(testX[:].get())\n",
    "\n",
    "print(trainPredict.shape)\n",
    "print(testPredict.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = testPredict\n",
    "testY = testY.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 解决中文显示问题\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "for i in range(50):\n",
    "    plt.figure( figsize=(100,10) )\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(testY[i*423:(i+1)*423])\n",
    "    plt.plot(testPredict[i*423:(i+1)*423]*testmax[kpi])\n",
    "    plt.title(f\"{kpi_name}测试集预测图{i}\",fontsize=100)\n",
    "    plt.legend(['testY',\"testYPredict\"],fontsize=50)\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(abs(testY[i*423:(i+1)*423]-testPredict[i*423:(i+1)*423]*testmax[kpi]))\n",
    "    plt.title(f\"{kpi_name}测试集误差图{i}\",fontsize=100)\n",
    "    plt.savefig(f'D:\\library\\Github\\Innovative-practice\\第三学期\\DATA\\pic\\lstm\\pred\\{kpi_name}\\{kpi_name}测试集预测图{i}.png')\n",
    "    plt.close()\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "RMSE为 8.60474944137078\n",
      "MAE为 5.535844061715677\n",
      "MAPE为 52.39164619161211\n",
      "R2为 0.7799865135413042\n"
     ]
    }
   ],
   "source": [
    "from  sklearn import  metrics\n",
    "import numpy as np\n",
    "\n",
    "def GetRMSE(y_hat,y_test):\n",
    "    sum = np.sqrt(metrics.mean_squared_error(y_test, y_hat))\n",
    "    return  sum\n",
    "\n",
    "def GetMAE(y_hat,y_test):\n",
    "    sum = metrics.mean_absolute_error(y_test, y_hat)\n",
    "    return  sum\n",
    "\n",
    "def GetMAPE_Order(y_hat,y_test):\n",
    "    #删除test_y 为0元素\n",
    "    zero_index = np.where(y_test == 0)\n",
    "    y_hat = np.delete(y_hat,zero_index[0])\n",
    "    y_test = np.delete(y_test,zero_index[0])\n",
    "    sum = np.mean(np.abs((y_hat - y_test) / y_test)) * 100\n",
    "    return sum\n",
    "#计算R2\n",
    "def GetR2(y_hat,y_test):\n",
    "    sum = metrics.r2_score(y_test, y_hat)\n",
    "    return sum\n",
    "print(type(testY))\n",
    "rmse=[]\n",
    "mae=[]\n",
    "mape_order=[]\n",
    "r2=[]\n",
    "testPredict1=testPredict*testmax[kpi]\n",
    "for i in range(100):\n",
    "    rmse.append(GetRMSE(testPredict1[i*423:(i+1)*423],testY[i*423:(i+1)*423]))\n",
    "    mae.append(GetMAE(testPredict1[i*423:(i+1)*423],testY[i*423:(i+1)*423]))\n",
    "    mape_order.append(GetMAPE_Order(testPredict1[i*423:(i+1)*423],testY[i*423:(i+1)*423]))\n",
    "    r2.append(GetR2(testPredict1[i*423:(i+1)*423],testY[i*423:(i+1)*423]))\n",
    "\n",
    "print(\"RMSE为\", np.mean(rmse))\n",
    "print(\"MAE为\", np.mean(mae))\n",
    "print(\"MAPE为\", np.mean(mape_order))\n",
    "print(\"R2为\", np.mean(r2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('Innovative-practice-HHChy52D')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1353927fb18e064046a1cd21ed8c15ef15c98edbe2136e1d2bceb4804e0d476f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
